{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1ec4e6-fcf4-4bd6-835f-65172eb9053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0551cdf5-ced6-4123-a168-067bb0dcca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8e7055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train = '/Users/myrthereuver/Documents/GitHub/argmining2022/TaskA_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ef43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dev = '/Users/myrthereuver/Documents/GitHub/argmining2022/TaskA_dev.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e17909",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = '/Users/myrthereuver/Documents/GitHub/argmining2022/TaskA_test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b86888f-2bb6-4d3c-abf0-d2a05cb20f46",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4304b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(input_file):\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    \n",
    "    df_current = pd.read_csv(input_file)\n",
    "    \n",
    "    # changing neutral to 1, as specified in the paper and data\n",
    "    df_current.loc[df_current[\"Validity\"] == 0, \"Validity\"] = 1\n",
    "    df_current.loc[df_current[\"Novelty\"] == 0, \"Novelty\"] = 1\n",
    "    \n",
    "    # adding the premise and conclusion to one text\n",
    "    df_current[\"examples\"] = df_current[\"Premise\"]+\" AND \"+df_current[\"Conclusion\"]\n",
    "    df_current[\"examples_topic\"] = df_current[\"topic\"]+ \" AND \"+df_current[\"Premise\"]+\" AND \"+df_current[\"Conclusion\"]\n",
    "    \n",
    "    # stemming\n",
    "    df_current[\"stemmed\"] = df_current[\"examples\"].apply(lambda row: \" \".join([stemmer.stem(w) for w in row.split(\" \")]))\n",
    "    df_current[\"stemmed_topic\"] = df_current[\"examples_topic\"].apply(lambda row: \" \".join([stemmer.stem(w) for w in row.split(\" \")]))\n",
    "    return df_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1962f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = create_df(file_train)\n",
    "data_dev = create_df(file_dev)\n",
    "data_test = create_df(file_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07db1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    595\n",
       " 1    155\n",
       "Name: Novelty, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"Novelty\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce42b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ed5216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202\n"
     ]
    }
   ],
   "source": [
    "print(len(data_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e50a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520\n"
     ]
    }
   ],
   "source": [
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edf218a-b907-4beb-a52e-fd8371137e74",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7e0dce-7a09-4a36-b33e-19ad4d93232a",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f9aade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_hyperparam = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC(C=0.09)),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e7eb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_model(model, validation, label, version_text):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    predicted = model.predict(validation[version_text])\n",
    "  \n",
    "    print(metrics.classification_report(validation[label], predicted, digits=4))\n",
    "    accuracy = np.mean(predicted == validation[label])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca6f516",
   "metadata": {},
   "source": [
    "### Validity, Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86ca470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val = text_clf_hyperparam.fit(data_train.stemmed, data_train.Validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8779195a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.6053    0.3108    0.4107        74\n",
      "           1     0.6890    0.8828    0.7740       128\n",
      "\n",
      "    accuracy                         0.6733       202\n",
      "   macro avg     0.6471    0.5968    0.5923       202\n",
      "weighted avg     0.6583    0.6733    0.6409       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val = results_model(model_val, data_dev, \"Validity\", \"stemmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21d256c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.4211    0.4660    0.4424       206\n",
      "           1     0.6233    0.5796    0.6007       314\n",
      "\n",
      "    accuracy                         0.5346       520\n",
      "   macro avg     0.5222    0.5228    0.5215       520\n",
      "weighted avg     0.5432    0.5346    0.5380       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val_test = results_model(model_val, data_test, \"Validity\", \"stemmed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2560abe",
   "metadata": {},
   "source": [
    "### Validity, Topic+stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "811df440",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_val_top = text_clf_hyperparam.fit(data_train.stemmed_topic, data_train.Validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e61821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.5263    0.2703    0.3571        74\n",
      "           1     0.6707    0.8594    0.7534       128\n",
      "\n",
      "    accuracy                         0.6436       202\n",
      "   macro avg     0.5985    0.5648    0.5553       202\n",
      "weighted avg     0.6178    0.6436    0.6083       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val_top = results_model(model_val_top, data_dev, \"Validity\", \"stemmed_topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b1a7981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.4382    0.5340    0.4814       206\n",
      "           1     0.6431    0.5510    0.5935       314\n",
      "\n",
      "    accuracy                         0.5442       520\n",
      "   macro avg     0.5407    0.5425    0.5374       520\n",
      "weighted avg     0.5620    0.5442    0.5491       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_val_topic_test = results_model(model_val_top, data_test, \"Validity\", \"stemmed_topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b094cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_hyperparam2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.LinearSVC(C=4.7)),\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f1e09",
   "metadata": {},
   "source": [
    "#### higher C is better for Novelty, but we will disregard that as we want one parameter for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aafe14",
   "metadata": {},
   "source": [
    "### Novelty, Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7dad6465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nov = text_clf_hyperparam.fit(data_train.stemmed, data_train.Novelty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd5b188e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.5842    1.0000    0.7375       118\n",
      "           1     0.0000    0.0000    0.0000        84\n",
      "\n",
      "    accuracy                         0.5842       202\n",
      "   macro avg     0.2921    0.5000    0.3687       202\n",
      "weighted avg     0.3412    0.5842    0.4308       202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_nov = results_model(model_nov, data_dev, \"Novelty\", \"stemmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e5915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.5654    1.0000    0.7224       294\n",
      "           1     0.0000    0.0000    0.0000       226\n",
      "\n",
      "    accuracy                         0.5654       520\n",
      "   macro avg     0.2827    0.5000    0.3612       520\n",
      "weighted avg     0.3197    0.5654    0.4084       520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_nov_test = results_model(model_nov, data_test, \"Novelty\", \"stemmed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ce086",
   "metadata": {},
   "source": [
    "### Novelty, Topic+stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c262129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nov_top = text_clf_hyperparam.fit(data_train.stemmed_topic, data_train.Novelty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "351da7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.5842    1.0000    0.7375       118\n",
      "           1     0.0000    0.0000    0.0000        84\n",
      "\n",
      "    accuracy                         0.5842       202\n",
      "   macro avg     0.2921    0.5000    0.3687       202\n",
      "weighted avg     0.3412    0.5842    0.4308       202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_nov_top = results_model(model_nov_top, data_dev, \"Novelty\", \"stemmed_topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2cb1e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1     0.5654    1.0000    0.7224       294\n",
      "           1     0.0000    0.0000    0.0000       226\n",
      "\n",
      "    accuracy                         0.5654       520\n",
      "   macro avg     0.2827    0.5000    0.3612       520\n",
      "weighted avg     0.3197    0.5654    0.4084       520\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/myrthereuver/tf-venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_nov_top_test = results_model(model_nov_top, data_test, \"Novelty\", \"stemmed_topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5f0675",
   "metadata": {},
   "source": [
    "### eval on Shared Task organizer's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e110f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import numpy\n",
    "\n",
    "def val_nov_metric(is_validity: numpy.ndarray, should_validity: numpy.ndarray, is_novelty: numpy.ndarray, should_novelty: numpy.ndarray) -> Dict[str, float]:\n",
    "    ret = dict()\n",
    "\n",
    "    ret_base_help = {\n",
    "        \"true_positive_validity\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity >= .5, should_validity >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_negative_validity\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity < .5, should_validity < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_positive_novelty\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_novelty >= .5, should_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_negative_novelty\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_novelty < .5, should_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_positive_valid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity >= .5, is_novelty >= .5,\n",
    "                                   should_validity >= .5, should_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_positive_nonvalid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity < .5, is_novelty >= .5,\n",
    "                                   should_validity < .5, should_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_positive_valid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity >= .5, is_novelty < .5,\n",
    "                                   should_validity >= .5, should_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"true_positive_nonvalid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity < .5, is_novelty < .5,\n",
    "                                   should_validity < .5, should_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"classified_positive_validity\": numpy.sum(numpy.where(is_validity >= .5, 1, 0)),\n",
    "        \"classified_negative_validity\": numpy.sum(numpy.where(is_validity < .5, 1, 0)),\n",
    "        \"classified_positive_novelty\": numpy.sum(numpy.where(is_novelty >= .5, 1, 0)),\n",
    "        \"classified_negative_novelty\": numpy.sum(numpy.where(is_novelty < .5, 1, 0)),\n",
    "        \"classified_positive_valid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity >= .5, is_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"classified_positive_nonvalid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity < .5, is_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"classified_positive_valid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity >= .5, is_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"classified_positive_nonvalid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([is_validity < .5, is_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"indeed_positive_validity\": numpy.sum(numpy.where(should_validity >= .5, 1, 0)),\n",
    "        \"indeed_negative_validity\": numpy.sum(numpy.where(should_validity < .5, 1, 0)),\n",
    "        \"indeed_positive_novelty\": numpy.sum(numpy.where(should_novelty >= .5, 1, 0)),\n",
    "        \"indeed_negative_novelty\": numpy.sum(numpy.where(should_novelty < .5, 1, 0)),\n",
    "        \"indeed_positive_valid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([should_validity >= .5, should_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"indeed_positive_nonvalid_novel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([should_validity < .5, should_novelty >= .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"indeed_positive_valid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([should_validity >= .5, should_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "        \"indeed_positive_nonvalid_nonnovel\": numpy.sum(numpy.where(\n",
    "            numpy.all(numpy.stack([should_validity < .5, should_novelty < .5]), axis=0),\n",
    "            1, 0)),\n",
    "    }\n",
    "\n",
    "    ret_help = {\n",
    "        \"precision_validity\": ret_base_help[\"true_positive_validity\"] /\n",
    "                              max(1, ret_base_help[\"classified_positive_validity\"]),\n",
    "        \"precision_novelty\": ret_base_help[\"true_positive_novelty\"] /\n",
    "                             max(1, ret_base_help[\"classified_positive_novelty\"]),\n",
    "        \"recall_validity\": ret_base_help[\"true_positive_validity\"] /\n",
    "                           max(1, ret_base_help[\"indeed_positive_validity\"]),\n",
    "        \"recall_novelty\": ret_base_help[\"true_positive_novelty\"] /\n",
    "                          max(1, ret_base_help[\"indeed_positive_novelty\"]),\n",
    "        \"precision_val_neg\": ret_base_help[\"true_negative_validity\"] /\n",
    "                              max(1, ret_base_help[\"classified_negative_validity\"]),\n",
    "        \"precision_nov_neg\": ret_base_help[\"true_negative_novelty\"] /\n",
    "                             max(1, ret_base_help[\"classified_negative_novelty\"]),\n",
    "        \"recall_val_neg\": ret_base_help[\"true_negative_validity\"] /\n",
    "                           max(1, ret_base_help[\"indeed_negative_validity\"]),\n",
    "        \"recall_nov_neg\": ret_base_help[\"true_negative_novelty\"] /\n",
    "                          max(1, ret_base_help[\"indeed_negative_novelty\"]),\n",
    "        \"precision_valid_novel\": ret_base_help[\"true_positive_valid_novel\"] /\n",
    "                                 max(1, ret_base_help[\"classified_positive_valid_novel\"]),\n",
    "        \"precision_valid_nonnovel\": ret_base_help[\"true_positive_valid_nonnovel\"] /\n",
    "                                    max(1, ret_base_help[\"classified_positive_valid_nonnovel\"]),\n",
    "        \"precision_nonvalid_novel\": ret_base_help[\"true_positive_nonvalid_novel\"] /\n",
    "                                    max(1, ret_base_help[\"classified_positive_nonvalid_novel\"]),\n",
    "        \"precision_nonvalid_nonnovel\": ret_base_help[\"true_positive_nonvalid_nonnovel\"] /\n",
    "                                       max(1, ret_base_help[\"classified_positive_nonvalid_nonnovel\"]),\n",
    "        \"recall_valid_novel\": ret_base_help[\"true_positive_valid_novel\"] /\n",
    "                              max(1, ret_base_help[\"indeed_positive_valid_novel\"]),\n",
    "        \"recall_valid_nonnovel\": ret_base_help[\"true_positive_valid_nonnovel\"] /\n",
    "                                 max(1, ret_base_help[\"indeed_positive_valid_nonnovel\"]),\n",
    "        \"recall_nonvalid_novel\": ret_base_help[\"true_positive_nonvalid_novel\"] /\n",
    "                                 max(1, ret_base_help[\"indeed_positive_nonvalid_novel\"]),\n",
    "        \"recall_nonvalid_nonnovel\": ret_base_help[\"true_positive_nonvalid_nonnovel\"] /\n",
    "                                    max(1, ret_base_help[\"indeed_positive_nonvalid_nonnovel\"])\n",
    "    }\n",
    "\n",
    "    ret.update({\n",
    "        \"f1_validity\": 2 * ret_help[\"precision_validity\"] * ret_help[\"recall_validity\"] / max(1e-4, ret_help[\"precision_validity\"] + ret_help[\"recall_validity\"]),\n",
    "        \"f1_novelty\": 2 * ret_help[\"precision_novelty\"] * ret_help[\"recall_novelty\"] / max(1e-4, ret_help[\"precision_novelty\"] + ret_help[\"recall_novelty\"]),\n",
    "        \"f1_val_neg\": 2 * ret_help[\"precision_val_neg\"] * ret_help[\"recall_val_neg\"] / max(1e-4, ret_help[\"precision_val_neg\"] + ret_help[\"recall_val_neg\"]),\n",
    "        \"f1_nov_neg\": 2 * ret_help[\"precision_nov_neg\"] * ret_help[\"recall_nov_neg\"] / max(1e-4, ret_help[\"precision_nov_neg\"] + ret_help[\"recall_nov_neg\"]),\n",
    "        \"f1_valid_novel\": 2 * ret_help[\"precision_valid_novel\"] * ret_help[\"recall_valid_novel\"] / max(1e-4, ret_help[\"precision_valid_novel\"] + ret_help[\"recall_valid_novel\"]),\n",
    "        \"f1_valid_nonnovel\": 2 * ret_help[\"precision_valid_nonnovel\"] * ret_help[\"recall_valid_nonnovel\"] / max(1e-4, ret_help[\"precision_valid_nonnovel\"] + ret_help[\"recall_valid_nonnovel\"]),\n",
    "        \"f1_nonvalid_novel\": 2 * ret_help[\"precision_nonvalid_novel\"] * ret_help[\"recall_nonvalid_novel\"] / max(1e-4, ret_help[\"precision_nonvalid_novel\"] + ret_help[\"recall_nonvalid_novel\"]),\n",
    "        \"f1_nonvalid_nonnovel\": 2 * ret_help[\"precision_nonvalid_nonnovel\"] * ret_help[\"recall_nonvalid_nonnovel\"] / max(1e-4, ret_help[\"precision_nonvalid_nonnovel\"] + ret_help[\"recall_nonvalid_nonnovel\"])\n",
    "    })\n",
    "\n",
    "    ret.update({\n",
    "        \"f1_val_macro\": (ret[\"f1_validity\"] + ret[\"f1_val_neg\"])/2,\n",
    "        \"f1_nov_macro\": (ret[\"f1_novelty\"] + ret[\"f1_nov_neg\"])/2,\n",
    "        \"f1_macro\": (ret[\"f1_valid_novel\"]+ret[\"f1_valid_nonnovel\"]+ret[\"f1_nonvalid_novel\"]+ret[\"f1_nonvalid_nonnovel\"])/4\n",
    "    })\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32a1dc",
   "metadata": {},
   "source": [
    "### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49d5f0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_validity': 0.773972602739726,\n",
       " 'f1_novelty': 0.0,\n",
       " 'f1_val_neg': 0.4107142857142857,\n",
       " 'f1_nov_neg': 0.7374999999999999,\n",
       " 'f1_valid_novel': 0.0,\n",
       " 'f1_valid_nonnovel': 0.6245059288537549,\n",
       " 'f1_nonvalid_novel': 0.0,\n",
       " 'f1_nonvalid_nonnovel': 0.417910447761194,\n",
       " 'f1_val_macro': 0.5923434442270059,\n",
       " 'f1_nov_macro': 0.36874999999999997,\n",
       " 'f1_macro': 0.2606040941537372}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_nov_metric(pred_val, np.array(data_dev[\"Validity\"]), pred_nov, np.array(data_dev[\"Novelty\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fcf370",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0b88134-0fbc-4b4a-92b5-2662eedb3dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_validity': 0.6006600660066006,\n",
       " 'f1_novelty': 0.0,\n",
       " 'f1_val_neg': 0.4423963133640553,\n",
       " 'f1_nov_neg': 0.7223587223587223,\n",
       " 'f1_valid_novel': 0.0,\n",
       " 'f1_valid_nonnovel': 0.453781512605042,\n",
       " 'f1_nonvalid_novel': 0.0,\n",
       " 'f1_nonvalid_nonnovel': 0.272189349112426,\n",
       " 'f1_val_macro': 0.521528189685328,\n",
       " 'f1_nov_macro': 0.36117936117936117,\n",
       " 'f1_macro': 0.181492715429367}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_nov_metric(pred_val_test, np.array(data_test[\"Validity\"]), pred_nov_test, np.array(data_test[\"Novelty\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1923722-d420-4a3c-82a4-8dbbcb80c5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f4b1a-fe91-4e21-9330-bdaf56f7c8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
