{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93183bc6-a325-4997-87af-912ee98e27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import TrainingArguments, set_seed\n",
    "\n",
    "from data import SharedTaskData\n",
    "from models import MultitaskModel\n",
    "from train_mtl import Tokenize, compute_metrics, prepare_data\n",
    "from trainers import MultitaskTrainer, NLPDataCollator, TASK_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Set variables.\n",
    "checkpoint: str = \"../../Downloads/checkpoint-470\"\n",
    "use_model: str = \"roberta-large-mnli\"\n",
    "seed: int = 0\n",
    "tensorflows: bool = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function map_label at 0x7ff53ef85160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([2, 1024]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large-mnli and are newly initialized because the shapes did not match:\n",
      "- classifier.out_proj.weight: found shape torch.Size([3, 1024]) in the checkpoint and torch.Size([2, 1024]) in the model instantiated\n",
      "- classifier.out_proj.bias: found shape torch.Size([3]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/750 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5feb0660314c4dfc80796904eceb7aaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a238c3ef0ea140e1a1ffca60b05e62a7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50a8111de1d64035a921b8a6f98ac755"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/202 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a0453e235a24756a02fce2ced293693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bc9800a4d0f4119bbc2b0cbdd6ca7cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a908ed6fb7d84ae68b9519f1eb772a5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a4ac7bf268f4c42994bf5c1b0076ff2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/750 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdc712c3fed64ca78547752b3e3272f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ffcda069e5f4070a8be2e471aff80dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85b7bf3038bb4f168edae005375b08b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/202 [00:00<?, ?ex/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b36125fba8463fbd30350a9adb7099"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db3d9481fd634548806b0aecd2871223"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8497048fb614cf79bf2f61c319bb921"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "548327105c4e4f92b1753ecca5584a8a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset.\n",
    "set_seed(seed)\n",
    "tokenize = Tokenize(use_model, tensorflows, \"concatenation\")\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "train_data = SharedTaskData(\"TaskA_train.csv\")\n",
    "dev_data = SharedTaskData(\"TaskA_dev.csv\")\n",
    "\n",
    "tokenized_train_dataset_novelty, tokenized_dev_dataset_novelty = prepare_data(\n",
    "    use_model,\n",
    "    train_data,\n",
    "    dev_data,\n",
    "    \"novelty\",\n",
    "    tokenize.tokenize_function_nov\n",
    ")\n",
    "tokenized_train_dataset_validity, tokenized_dev_dataset_validity = prepare_data(\n",
    "    use_model,\n",
    "    train_data,\n",
    "    dev_data,\n",
    "    \"validity\",\n",
    "    tokenize.tokenize_function_val\n",
    ")\n",
    "\n",
    "if \"ArgumentRelation\" in use_model:\n",
    "    kwargs = {'pad_token_id': 1}\n",
    "else:\n",
    "    kwargs = {}\n",
    "\n",
    "# Load model.\n",
    "multitask_model = MultitaskModel.create(\n",
    "    model_name=use_model,\n",
    "    model_type_dict={\n",
    "        \"novelty\": transformers.AutoModelForSequenceClassification,\n",
    "        \"validity\": transformers.AutoModelForSequenceClassification,\n",
    "    },\n",
    "    model_config_dict={\n",
    "        \"novelty\": transformers.AutoConfig.from_pretrained(use_model, num_labels=2, **kwargs),\n",
    "        \"validity\": transformers.AutoConfig.from_pretrained(use_model, num_labels=2, **kwargs),\n",
    "    },\n",
    "    tensorflows=tensorflows\n",
    ")\n",
    "\n",
    "multitask_model.load_trainer_checkpoint(checkpoint)\n",
    "\n",
    "# Load trainer/evaluator.\n",
    "val_dataset = {\n",
    "    \"novelty\": tokenized_dev_dataset_novelty,\n",
    "    \"validity\": tokenized_dev_dataset_validity,\n",
    "}\n",
    "\n",
    "train_dataset = {\n",
    "    \"novelty\": tokenized_train_dataset_novelty,\n",
    "    \"validity\": tokenized_train_dataset_validity,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    f\"hftrainer_am_mtl_{use_model}_{seed}\",\n",
    "    label_names=['labels']\n",
    ")\n",
    "\n",
    "trainer = MultitaskTrainer(\n",
    "    model=multitask_model,\n",
    "    data_collator=NLPDataCollator(tokenizer=tokenize.tokenizer),\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenize.tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    args=training_args,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n",
      "***** Running Prediction *****\n",
      "  Num examples = 202\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating novelty\n",
      "Evaluating validity\n",
      "novelty: Amount of mistakes: 50\n",
      "validity: Amount of mistakes: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/26 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions on validation set.\n",
    "outputs = trainer.predict(val_dataset)\n",
    "\n",
    "for task in TASK_NAMES:\n",
    "    print(f\"{task}: Amount of mistakes: {torch.sum(outputs[task]['predictions'] != torch.tensor(outputs[task]['labels']))}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urjakhurana/miniconda3/envs/argmining2022/lib/python3.8/site-packages/pandas/core/indexing.py:1503: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  key = np.asarray(key)\n",
      "/Users/urjakhurana/miniconda3/envs/argmining2022/lib/python3.8/site-packages/pandas/core/indexing.py:1503: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  key = np.asarray(key)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get (mis-)classification of predictions based on confidence of annotation.\n",
    "%matplotlib inline\n",
    "task = \"novelty\"\n",
    "\n",
    "# Retrieve confidences of the mistakes and correct classifications.\n",
    "idxs = (outputs[task]['predictions'] != torch.tensor(outputs[task]['labels'])).nonzero()\n",
    "confs_mistakes = dev_data.df.iloc[list(idxs)][f\"{task.capitalize()}-Confidence\"]\n",
    "idxs = (outputs[task]['predictions'] == torch.tensor(outputs[task]['labels'])).nonzero()\n",
    "confs_correct = dev_data.df.iloc[list(idxs)][f\"{task.capitalize()}-Confidence\"]\n",
    "\n",
    "# Normalize over the total count of mistakes and corrects respectively.\n",
    "confs_mistakes = {k: v / confs_mistakes.count() for k, v in confs_mistakes.value_counts().to_dict().items()}\n",
    "confs_correct = {k: v / confs_correct.count() for k, v in confs_correct.value_counts().to_dict().items()}\n",
    "\n",
    "# Uncomment if background is black so text of plot is white.\n",
    "# params = {\"ytick.color\" : \"w\",\n",
    "#           \"xtick.color\" : \"w\",\n",
    "#           \"axes.labelcolor\" : \"w\",\n",
    "#           \"axes.edgecolor\" : \"w\"}\n",
    "# plt.rcParams.update(params)\n",
    "# plt.title(f\"{task.capitalize()}-Confidence\", color=\"w\")\n",
    "\n",
    "np.random.seed(0)\n",
    "plt.xticks(range(len(list(confs_correct.keys()))), list(confs_correct.keys()))\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Relative Frequency')\n",
    "plt.title(f\"{task.capitalize()}-Confidence\")\n",
    "\n",
    "width = 0.3\n",
    "plt.bar(range(len(confs_correct.keys())), [confs_mistakes.get(k, 0) for k in confs_correct.keys()], label=\"mistakes\", width=width)\n",
    "plt.bar(np.arange(len(confs_correct)) + width, confs_correct.values(), label=\"correct\", width=width)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'non-valid;non-novel': 0.14285714285714285, 'non-valid;novel': 0.22448979591836735, 'valid;non-novel': 0.40816326530612246, 'valid;novel': 0.20408163265306123}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/urjakhurana/miniconda3/envs/argmining2022/lib/python3.8/site-packages/pandas/core/indexing.py:1503: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  key = np.asarray(key)\n",
      "/Users/urjakhurana/miniconda3/envs/argmining2022/lib/python3.8/site-packages/pandas/core/indexing.py:1503: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  key = np.asarray(key)\n"
     ]
    }
   ],
   "source": [
    "# Get distribution of mistakes over combined labels.\n",
    "task = \"validity\"\n",
    "\n",
    "idxs = (outputs[task]['predictions'] != torch.tensor(outputs[task]['labels'])).nonzero()\n",
    "val_mistakes = dev_data.df.iloc[list(idxs)][\"Validity\"]\n",
    "nov_mistakes = dev_data.df.iloc[list(idxs)][\"Novelty\"]\n",
    "\n",
    "counts = defaultdict(int)\n",
    "for val_mistake, nov_mistake in zip(val_mistakes, nov_mistakes):\n",
    "    if val_mistake == -1 and nov_mistake == -1:\n",
    "        counts[\"non-valid;non-novel\"] += 1\n",
    "    elif val_mistake == 1 and nov_mistake == -1:\n",
    "        counts[\"valid;non-novel\"] += 1\n",
    "    elif val_mistake == -1 and nov_mistake == 1:\n",
    "        counts[\"non-valid;novel\"] += 1\n",
    "    elif val_mistake == 1 and nov_mistake == 1:\n",
    "        counts[\"valid;novel\"] += 1\n",
    "\n",
    "counts = {k: v / len(val_mistakes) for k, v in counts.items()}\n",
    "print(counts)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Vegetarianism                                   0.200000\nVideo surveillance                              0.473684\nWar on Drugs                                    0.188406\nWarrantless wiretapping in the United States    0.260870\nWave power                                      0.217391\nWind energy                                     0.208333\nYucca Mountain nuclear waste repository         0.235294\nZoos                                            0.571429\nName: topic, dtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get percentage of mistakes per topic.\n",
    "task = \"novelty\"\n",
    "idxs = (outputs[task]['predictions'] != torch.tensor(outputs[task]['labels'])).nonzero()\n",
    "topics_mistakes = dev_data.df.iloc[list(idxs)][\"topic\"]\n",
    "\n",
    "topics_mistakes.value_counts() / dev_data.df[\"topic\"].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}